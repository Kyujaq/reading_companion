# Reading Companion

An interactive web-based phonics and reading assistant for English and French children (ages 4‚Äì8). The app works **fully offline** with no external dependencies ‚Äî the core runs entirely in the browser using the Web Speech API. Optional companion services (Vosk, Ollama, YOLO) activate automatically when reachable, and the app degrades gracefully when they are not.

---

## Features

### üî§ Letters & Syllables
- Interactive consonant/vowel keyboard ‚Äî click or type to hear sounds
- Syllable builder: combine consonant + vowel and hear the result
- Common syllable buttons for quick access
- Word builder from syllables with automatic word detection
- Physical keyboard support

### üñºÔ∏è Picture Gallery *(Phase 2)*
- 20+ emoji word cards per language (Fruits, Animals, Vehicles, Home)
- Click any card to hear TTS + animated syllable breakdown
- Category filter buttons
- "Spell it!" button on each card launches a guided typing lesson

### üéì Instruction Mode *(Phase 1)*
- Step-by-step phonics lessons with TTS spoken guidance
- Lessons for French (V√âLO, CHAT, A B C) and English (CAT, DOG, A B C)
- Expected letter highlighted with pulsing glow on the keyboard
- Progress bar showing current step vs total steps
- Session report at completion with correct-answer stats
- "Spell it!" from the Gallery and Camera generate lessons automatically from any word

### üé§ Voice Input ‚Äî Vosk STT *(Phase 3)*
- When the Vosk WebSocket server is running on `ws://localhost:2700`, a üé§ indicator appears
- In Instruction Mode the app listens for the expected letter/word after each TTS prompt
- Grammar is narrowed to the expected input for accuracy
- Button input always works as fallback

### ü§ñ AI Tutor ‚Äî Ollama *(Phase 4)*
- When Ollama is reachable at `http://192.168.2.205:11434`, a ü§ñ indicator appears
- Dynamic, personalised encouragement replaces canned responses in Instruction Mode
- Session completion summary generated by the LLM
- Toggle on/off and set the child's name in the ‚öôÔ∏è Settings panel
- Falls back to canned text automatically if Ollama times out

### üì∑ Camera Mode ‚Äî YOLO *(Phase 5)*
- The üì∑ Camera tab appears only when the YOLO server is reachable
- Take a photo with the device camera or upload an image
- Detected objects shown as clickable cards with "Hear it", "Spell it!", and "First letter?" buttons
- Fun TTS narration of detected objects
- Graceful fallback message if no objects are detected

### üåç Bilingual
- Full English / French toggle ‚Äî all UI, lessons, and TTS adapt to the selected language
- French mode uses recorded phonetic audio files for accuracy

### üì± Touch & Keyboard Friendly
- All tap targets ‚â• 44 √ó 44 px
- Responsive layout for phones, tablets, and desktops
- No external libraries ‚Äî zero network requests in offline mode

---

## Quick Start

Open `index.html` in a modern browser. That's it ‚Äî no build step required.

```bash
# Optionally serve via a local server for the best experience:
python3 -m http.server 8000
# then open http://localhost:8000
```

---

## Optional Companion Services

| Service | Purpose | Default address | Setup |
|---|---|---|---|
| Vosk WebSocket server | Offline speech recognition | `ws://localhost:2700` | See [vosk-server/README.md](vosk-server/README.md) |
| Ollama | AI coaching & dynamic TTS | `http://192.168.2.205:11434` | Install Ollama, run `ollama pull llama3` |
| YOLO object detection | Camera word discovery | `http://localhost:8501` | Run your YOLO server |

All services are optional. The app works without any of them.

### Setting up Vosk (offline speech recognition)

See **[vosk-server/README.md](vosk-server/README.md)** for full instructions. Quick summary:

```bash
# 1. Download a model (French example):
#    https://alphacephei.com/vosk/models/vosk-model-small-fr-0.22.zip
#    Extract to vosk-server/models/fr/

# 2. Install dependencies:
cd vosk-server
pip install -r requirements.txt

# 3. Start the server:
python server.py
```

### Setting up Ollama

```bash
# Install Ollama: https://ollama.com
ollama pull llama3   # or mistral, phi3, etc.
ollama serve         # runs on port 11434 by default
```

---

## Architecture

```
index.html          ‚Äî Shell, tabs, overlays
script.js           ‚Äî Core ReadingCompanion class (offline, no deps)
instruction-mode.js ‚Äî Phase 1: InstructionSession, FeedbackEngine, SessionLogger
gallery.js          ‚Äî Phase 2: GalleryManager, emoji word cards
vosk-client.js      ‚Äî Phase 3: VoskClient WebSocket STT integration
ollama-coach.js     ‚Äî Phase 4: OllamaCoach LLM + SettingsManager
yolo-camera.js      ‚Äî Phase 5: YoloCameraManager camera + object detection
style.css           ‚Äî All styles
vosk-server/        ‚Äî Python WebSocket server for Vosk STT
phonetic/           ‚Äî French phonetic audio files
```

**Principle:** The core (`script.js`) has zero external dependencies and works offline.
Each companion module gracefully no-ops when its service is unreachable.

---

## Customization

### Adding words
Edit `languageData` in `script.js`:
```javascript
words: ['word1', 'word2', ...]
```

### Adding stories
```javascript
stories: [{ title: 'My Story', text: 'Click any word to hear it.' }]
```

### Adding lessons
Add entries to `LESSONS.fr` or `LESSONS.en` in `instruction-mode.js`.

### Adding gallery items
Add entries to `GALLERY_DATA.fr` or `GALLERY_DATA.en` in `gallery.js`.

---

## Browser Requirements

- Chrome 80+ / Edge 80+ / Safari 14+ / Firefox 75+
- Web Speech API (TTS) ‚Äî supported in all modern browsers
- `getUserMedia` ‚Äî required for camera and microphone features

---

## License

Open source ‚Äî free to use and modify.

## Contributing

Issues and pull requests welcome!
